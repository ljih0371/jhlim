{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workspce Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.PipelineRun = azureml.pipeline.core.run:PipelineRun._from_dto with exception (azureml-core 1.46.0 (c:\\users\\limjh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages), Requirement.parse('azureml-core~=1.45.0')).\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.ReusedStepRun = azureml.pipeline.core.run:StepRun._from_reused_dto with exception (azureml-core 1.46.0 (c:\\users\\limjh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages), Requirement.parse('azureml-core~=1.45.0')).\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.StepRun = azureml.pipeline.core.run:StepRun._from_dto with exception (azureml-core 1.46.0 (c:\\users\\limjh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages), Requirement.parse('azureml-core~=1.45.0')).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.46.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import azureml.core\n",
    "from azureml.core.authentication import ServicePrincipalAuthentication\n",
    "\n",
    "from azureml.core import (\n",
    "    Workspace,\n",
    "    Experiment,\n",
    "    Dataset,\n",
    "    Datastore,\n",
    "    ComputeTarget,\n",
    "    Environment,\n",
    "    ScriptRunConfig\n",
    ")\n",
    "\n",
    "from azureml.pipeline.core import (\n",
    "    Pipeline,\n",
    "    PipelineData,\n",
    "    PipelineEndpoint,\n",
    "    PublishedPipeline,\n",
    "    PipelineRun,\n",
    "    InputPortBinding\n",
    ")\n",
    "\n",
    "from azureml.pipeline.steps import (\n",
    "    PythonScriptStep,\n",
    "    DataTransferStep\n",
    ")\n",
    "from azureml.pipeline.core.graph import PipelineParameter\n",
    "\n",
    "from azureml.data.datapath import (\n",
    "    DataPath, \n",
    "    DataPathComputeBinding, \n",
    "    DataReference\n",
    ")\n",
    "\n",
    "from azureml.data import (OutputFileDatasetConfig)\n",
    "from azureml.data.dataset_consumption_config import DatasetConsumptionConfig\n",
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "\n",
    "from azure.ai.ml import Input\n",
    "\n",
    "print(\"SDK version:\", azureml.core.VERSION)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlw-mlops-dev-002\n",
      "MLOps_POC\n",
      "7722d447-2b14-4ca2-83c1-b4df9454a55a\n"
     ]
    }
   ],
   "source": [
    "## 작업 영역 연결\n",
    "\n",
    "svc_pr= ServicePrincipalAuthentication(\n",
    "    tenant_id=\"247258cc-5eb2-4fd4-9bb2-f272103f0c34\",\n",
    "    service_principal_id=\"b7cfba68-a51b-4ae3-8885-cef273960a5e\",\n",
    "    service_principal_password=\"d4f8Q~~8tUXmQelSJyquy7lys17-t8gecKXCrb47\")\n",
    "\n",
    "\n",
    "ws = Workspace.get(subscription_id=\"7722d447-2b14-4ca2-83c1-b4df9454a55a\",\n",
    "                    resource_group=\"MLOps_POC\",\n",
    "                    name=\"mlw-mlops-dev-002\",\n",
    "                    auth=svc_pr)\n",
    "\n",
    "print(ws.name, ws.resource_group, ws.subscription_id, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment / Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python_pipeline\n",
      "Run configuration created.\n"
     ]
    }
   ],
   "source": [
    "## Experiment\n",
    "experiment_folder = 'python_pipeline'\n",
    "os.makedirs(experiment_folder, exist_ok = True)\n",
    "\n",
    "print(experiment_folder)\n",
    "\n",
    "# choose a name for your cluster\n",
    "cluster_name = \"cluster-mlops-jh\"\n",
    "\n",
    "## environment 생성 및 등록\n",
    "experiment_env = Environment.from_conda_specification(\"Experiment_env\", experiment_folder + \"/conda.yml\")\n",
    "experiment_env.register(workspace=ws)\n",
    "\n",
    "## environment 연결\n",
    "registered_env = Environment.get(ws, 'Experiment_env')\n",
    "pipeline_run_config = RunConfiguration()\n",
    "pipeline_run_config.target = cluster_name\n",
    "pipeline_run_config.environment = registered_env\n",
    "\n",
    "print(\"Run configuration created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datastore / Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"busandatastore\",\n",
      "  \"container_name\": \"busan\",\n",
      "  \"account_name\": \"dlsmlopsdev002\",\n",
      "  \"protocol\": \"https\",\n",
      "  \"endpoint\": \"core.windows.net\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "## 작업 영역에서 datasotre 가져오기 \n",
    "datastore = Datastore.get(ws, 'busandatastore')\n",
    "print(datastore)\n",
    "\n",
    "## input Dataset \n",
    "\n",
    "train_dataset = Dataset.get_by_name(ws,'tab_pvprediction_train')\n",
    "test_dataset = Dataset.get_by_name(ws,'tab_pvprediction_test')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline train steps defined\n",
      "Pipeline score steps defined\n",
      "Pipeline evaluate steps defined\n"
     ]
    }
   ],
   "source": [
    "## 각 스텝 output \n",
    "## PipelineData : 파이프라인의 중간 데이터\n",
    "\n",
    "model = PipelineData(\"model\",\n",
    "                     data_type = \"UriFolder\", \n",
    "                     output_mode='upload',\n",
    "                     output_path_on_compute = \"//datastores/busandatastore/paths/azureml/{name}/model/\")\n",
    "\n",
    "scored_data = PipelineData(\"scored_data\", \n",
    "                            data_type = \"UriFolder\", \n",
    "                            output_mode='upload',\n",
    "                            output_path_on_compute = \"//datastores/busandatastore/paths/azureml/{name}/scored_data/\")\n",
    "\n",
    "## train_step 파라미터값\n",
    "param_location = PipelineParameter(name=\"location\", default_value=\"busan\")\n",
    "param_test_size = PipelineParameter(name=\"test_size\", default_value=0.3)\n",
    "param_shuffle = PipelineParameter(name=\"shuffle\", default_value=True)\n",
    "param_random_state = PipelineParameter(name=\"random_state\", default_value=34)\n",
    "param_message = PipelineParameter(name=\"message\", default_value=\"AddParameterTest\")\n",
    "\n",
    "train_pipeline_param = PipelineParameter(name=\"traindata_param\", \n",
    "                                         default_value=train_dataset)\n",
    "traindata_input = DatasetConsumptionConfig(\"traindata\",train_pipeline_param)\n",
    "\n",
    "## score_step 파라미터값\n",
    "test_pipeline_param = PipelineParameter(name=\"testdata_param\", \n",
    "                                           default_value=test_dataset)\n",
    "\n",
    "## DatasetConsumptionConfig : 데이터 세트를 컴퓨팅 대상에 전달\n",
    "testdata_input = DatasetConsumptionConfig(\"testdata\",test_pipeline_param)\n",
    "\n",
    "## step 생성\n",
    "\n",
    "train_step = PythonScriptStep(\n",
    "    name=\"train step\",\n",
    "    source_directory=experiment_folder,\n",
    "    script_name=\"train_model.py\",\n",
    "    arguments=[ \"--model-path\", model,\n",
    "                \"--location\", param_location, \n",
    "                \"--test-size\", param_test_size, \n",
    "                \"--shuffle\" , param_shuffle, \n",
    "                \"--random-state\" , param_random_state, \n",
    "                \"--message\", param_message,\n",
    "                \"--param1\", traindata_input], \n",
    "    \n",
    "    inputs=[traindata_input],\n",
    "    outputs= [model],\n",
    "    \n",
    "    compute_target=cluster_name,\n",
    "    runconfig=pipeline_run_config,\n",
    "    allow_reuse=True\n",
    ")\n",
    "\n",
    "print(\"Pipeline train steps defined\")\n",
    "\n",
    "\n",
    "\n",
    "score_step = PythonScriptStep(\n",
    "    name=\"score step\",\n",
    "    source_directory=experiment_folder,\n",
    "    script_name=\"score_model.py\",\n",
    "    \n",
    "    arguments=[\"--model-path\", model,\n",
    "               \"--param1\", testdata_input,\n",
    "               \"--scoreddata-path\", scored_data],\n",
    "    \n",
    "    inputs=[testdata_input, model],\n",
    "    outputs=[scored_data],\n",
    "    \n",
    "    compute_target=cluster_name,\n",
    "    runconfig=pipeline_run_config,\n",
    "    allow_reuse=True\n",
    ")\n",
    "print(\"Pipeline score steps defined\")\n",
    "\n",
    "\n",
    "\n",
    "evaluate_step = PythonScriptStep(\n",
    "    name=\"evaluate step\",\n",
    "    source_directory=experiment_folder,\n",
    "    script_name=\"evaluate_model.py\",\n",
    "    arguments=[\"--scoreddata-path\", scored_data],\n",
    "    inputs=[scored_data],\n",
    "    compute_target=cluster_name,\n",
    "    runconfig=pipeline_run_config,\n",
    "    allow_reuse=True\n",
    ")\n",
    "print(\"Pipeline evaluate steps defined\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline is built\n",
      "Created step train step [d192e666][a4d3f6d4-196c-4e95-bf1c-5f6eb34148fe], (This step will run and generate new outputs)\n",
      "Created step score step [b473c85f][4b51a34e-a5c6-45e0-86d6-8d7e2184c9a4], (This step will run and generate new outputs)\n",
      "Created step evaluate step [9cd97da6][308d62d6-7f2b-4f74-a277-ae552d2854e2], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun 97ce22db-c41d-4be4-858e-cffc8fa9358d\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/97ce22db-c41d-4be4-858e-cffc8fa9358d?wsid=/subscriptions/7722d447-2b14-4ca2-83c1-b4df9454a55a/resourcegroups/MLOps_POC/workspaces/mlw-mlops-dev-002&tid=247258cc-5eb2-4fd4-9bb2-f272103f0c34\n",
      "Pipeline submitted for execution.\n",
      "PipelineRunId: 97ce22db-c41d-4be4-858e-cffc8fa9358d\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/97ce22db-c41d-4be4-858e-cffc8fa9358d?wsid=/subscriptions/7722d447-2b14-4ca2-83c1-b4df9454a55a/resourcegroups/MLOps_POC/workspaces/mlw-mlops-dev-002&tid=247258cc-5eb2-4fd4-9bb2-f272103f0c34\n",
      "PipelineRun Status: Running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Expected a StepRun object but received <class 'azureml.core.run.Run'> instead.\n",
      "This usually indicates a package conflict with one of the dependencies of azureml-core or azureml-pipeline-core.\n",
      "Please check for package conflicts in your python environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 파이프라인 실행\n",
    "\n",
    "pipeline_steps = [train_step, score_step, evaluate_step]\n",
    "pipeline = Pipeline(workspace=ws, steps=pipeline_steps)\n",
    "print(\"Pipeline is built\")\n",
    "\n",
    "## Experiment 개체 생성\n",
    "exp = Experiment(workspace=ws,name=\"Pipeline_python_jh\")\n",
    "\n",
    "pipeline_run = exp.submit(pipeline,regenerate_outputs = True)\n",
    "print(\"Pipeline submitted for execution.\")\n",
    "\n",
    "pipeline_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3335486d84fce0a15d9b8359c7f75eef8841ddabe681c849f2c41d9c2eb61c1d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
