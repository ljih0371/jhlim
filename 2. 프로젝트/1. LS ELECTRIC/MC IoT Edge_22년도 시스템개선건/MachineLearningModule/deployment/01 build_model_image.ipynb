{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "check version"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure ML SDK Version:  1.19.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import azureml.core\n",
    "from azureml.core import Workspace, Model\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "# display the core SDK version number\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"04.00.00\"\n",
    "MODEL_DESC = \"train data 2020-01-08 - 20020-01-28 / JYTek / Ferrite Core Applied / Use Only Test 2, 3 / Notch Filter Applied /= 04.00.00\"\n",
    "IMG_DESC = \"MCTFT 개선모델 최종버전에 테스트2,3 만 적용하도록 수정 / Feature 저장 기능 추가\"\n",
    "WORKSPACE = \"develope\" # develope, production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01 Azure ML Service 작업 영역에 연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기계학습이름:lsmc-dev-mlws\n",
      "리소스그룹이름:lsmc-prd-rg\n",
      "리전이름:koreacentral\n",
      "구독ID:1f154107-bef0-481f-a741-68e7ba34affe\n"
     ]
    }
   ],
   "source": [
    "if WORKSPACE == \"develope\":\n",
    "    ws_dir = \"config/config_dev.json\"\n",
    "elif WORKSPACE == \"production\":\n",
    "    ws_dir = \"config/config.json\"\n",
    "    \n",
    "ws = Workspace.from_config(\"config/config_dev.json\")\n",
    "print('기계학습이름:'+ws.name, '리소스그룹이름:'+ws.resource_group, '리전이름:'+ws.location, '구독ID:'+ws.subscription_id, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02 모델 등록"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 가져오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 방법 1. models 경로에 직접 파일을 저장\n",
    "- 방법 2.  개발과정에서 등록한 모델 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'04.00.00': Model(workspace=Workspace.create(name='lsmc-op-ml', subscription_id='1f154107-bef0-481f-a741-68e7ba34affe', resource_group='is-mc-analysis'), name=04.00.00, id=04.00.00:7, version=7, tags={'area': 'IoT Edge', 'type': 'azureml-automl'}, properties={})}\n",
      "\n",
      "Downloaded File: model_v2.pkl\n",
      "\n",
      "is Modified to: 04.00.00.pkl\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ws_model = Workspace.from_config(\"../.azureml/config.json\")\n",
    "print(ws_model.models)\n",
    "model = Model(ws_model, '04.00.00', version=6)\n",
    "model.download(target_dir='models/tmp/', exist_ok=True)\n",
    "donwloaded_file = os.listdir('models/tmp/')[0]\n",
    "os.rename(f\"models/tmp/{donwloaded_file}\", f\"models/{MODEL_NAME}.pkl\")\n",
    "os.rmdir(\"models/tmp/\")\n",
    "print(f\"\\nDownloaded File: {donwloaded_file}\\n\")\n",
    "print(f\"is Modified to: {MODEL_NAME}.pkl\\n\")\n",
    "file_name = f\"{MODEL_NAME}.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 등록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model 04.00.00\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "#library_version = \"DL\"+sklearn.__version__.replace(\".\",\"x\")\n",
    "model = Model.register(model_path = f\"models/{MODEL_NAME}.pkl\",\n",
    "                       model_name = MODEL_NAME,\n",
    "                       tags = {'area': \"IoT Edge\", 'type': \"azureml-automl\"},\n",
    "                       description = MODEL_DESC,\n",
    "                       workspace = ws_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'azureml-models/04.00.00/8/04.00.00.pkl'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model.get_model_path(MODEL_NAME, _workspace=ws_model)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 모델 실행 환경 세팅 파일(config/myenv.yml) 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pip packages: ['numpy==1.18.5', 'pandas==0.25.3', 'sqlalchemy==1.3.21', 'h5py==2.10.0', 'tqdm==4.54.0', 'obspy==1.2.2', 'azure-storage-blob==12.6.0', 'mysql-connector-python==8.0.18', 'azureml==0.2.7', 'azureml-core==1.19.0', 'azureml-sdk==1.19.0', 'scipy==1.6.0', 'xgboost==0.90']\n",
      "conda packasges: ['python=3.7.9', 'gcc_linux-64', 'pyyaml']\n"
     ]
    }
   ],
   "source": [
    "pip_packages = [\"numpy==1.18.5\",\n",
    "                \"pandas==0.25.3\",\n",
    "                \"sqlalchemy==1.3.21\",\n",
    "                \"h5py==2.10.0\",\n",
    "                \"tqdm==4.54.0\",\n",
    "                \"obspy==1.2.2\",\n",
    "                \"azure-storage-blob==12.6.0\",\n",
    "                \"mysql-connector-python==8.0.18\",\n",
    "                \"azureml==0.2.7\",\n",
    "                \"azureml-core==1.19.0\",\n",
    "                \"azureml-sdk==1.19.0\",\n",
    "                \"scipy==1.6.0\",\n",
    "                \"xgboost==0.90\"]\n",
    "\n",
    "lib_config_load = ['pyyaml']\n",
    "lib_clfs = [\"python=3.7.9\",\n",
    "            \"gcc_linux-64\"]\n",
    "\n",
    "conda_packages = lib_clfs + lib_config_load\n",
    "\n",
    "print('pip packages:', pip_packages)\n",
    "print('conda packasges:', conda_packages)\n",
    "\n",
    "\n",
    "myenv = CondaDependencies.create(conda_packages=conda_packages, pip_packages=pip_packages)\n",
    "myenv.add_channel('conda-forge')\n",
    "myenv.add_channel('defaults')\n",
    "\n",
    "with open(\"config/myenv.yml\",\"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 전처리 및 ML 판정 수행 로직 실행 스크립트(score_iot.py) 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'test'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-922d26b2471f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'test'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.listdir(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile score.py\n",
    "def init():\n",
    "    global loaded_model, model_object, model_version, column_names, line, cut_off, rule_model_params, model_path\n",
    "    \n",
    "    ## 수정필요  --------------------------------------------------------\n",
    "    model_object = model_v03_01_00\n",
    "    model_version = '03.01.00' #model_name 입력\n",
    "    column_names = [\"FTUR_CPSR_MAX_N1\",\"FTUR_CPSR_MAX_N2\",\"FTUR_CPSR_MAX_N3\",\"FTUR_CPSR_MAX_N4\",\n",
    "                    \"FTUR_CPSR_CRSTFT_N1\",\"FTUR_CPSR_CRSTFT_N2\",\"FTUR_CPSR_CRSTFT_N3\",\"FTUR_CPSR_CRSTFT_N4\"]\n",
    "    ## ----------------------------------------------------------------\n",
    "    file_name = '{}.pickle'.format(model_version)\n",
    "    edge_config = '/home/data/edge_config.yml'\n",
    "        \n",
    "    #load model\n",
    "    model_path = Model.get_model_path(file_name) \n",
    "    with open(model_path, \"rb\") as f:\n",
    "        loaded_model = pickle.load(f)\n",
    "        \n",
    "    #load line info\n",
    "    with open(edge_config , 'r') as stream:\n",
    "        try:\n",
    "            edge_config = yaml.load(stream, Loader=yaml.BaseLoader)\n",
    "            line = edge_config['config']['line']['name']\n",
    "            cut_off = float(edge_config['config']['param']['cutoff'])\n",
    "            rule_model_params = edge_config['config']['param']['rule_model']\n",
    "            \n",
    "        except yaml.YAMLError as exc:\n",
    "            print(\"line config error: \",exc)\n",
    "    \n",
    "    error_dir = '/home/data/error_file/'\n",
    "    try:\n",
    "        os.makedirs(error_dir, mode = 777)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def run(input_json):\n",
    "    print('\\n','mlmodule start')\n",
    "    print('\\n',datetime.now()+ timedelta(hours=9),'\\n')\n",
    "    #for test#\n",
    "    input_json = json.loads(input_json)\n",
    "    print('\\n','json loaded','\\n')\n",
    "    print(input_json, '\\n')\n",
    "    mltime = datetime.now() + timedelta(hours=9)\n",
    "    chtime = input_json['chtime']\n",
    "    print('chtime : ', chtime)\n",
    "    ct = datetime.strptime(chtime.replace('T',' ').split('+')[0][:-1], '%Y-%m-%d %H:%M:%S.%f')\n",
    "    diff = mltime-ct\n",
    "    input_json['chtime'] = str(ct)\n",
    "    input_json['mltime'] = str(mltime)\n",
    "    input_json['etime_ch'] = diff.seconds + diff.microseconds/1E6\n",
    "       \n",
    "    \n",
    "    #file load\n",
    "    init_time = time.time()\n",
    "    #input_json = json.loads(input_json)\n",
    "    input_path = input_json['path']\n",
    "    print('\\n', input_path)\n",
    "    \n",
    "    for attempt in range(3):\n",
    "        try:\n",
    "            print('Attempt: ' + str(attempt+1) + '  Time: ' + str(datetime.now()))\n",
    "            with h5py.File(input_path, 'r') as f:\n",
    "                tmp = f['Raw'][:]\n",
    "            input_raw = pd.DataFrame(tmp, columns=['x1','x2','x3'])\n",
    "            print('\\n', 'hdf loaded')\n",
    "\n",
    "        except Exception as ex: \n",
    "            if attempt == 2:\n",
    "                ex_message = str(ex)\n",
    "            \n",
    "            sleep(0.02)\n",
    "            continue\n",
    "        \n",
    "        break\n",
    "        \n",
    "    else:    \n",
    "        input_json['b'] = 2\n",
    "        input_json['prob'] = 2\n",
    "        input_json['error'] = ex_message\n",
    "        input_json['etime'] = time.time() - init_time\n",
    "\n",
    "        result_json =  [json.dumps(input_json)]\n",
    "        print('*'*5,' ','LOAD ERROR',' ','*'*5)\n",
    "        print(result_json)\n",
    "        try:\n",
    "            shutil.copy(input_path, error_dir)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    #for test#\n",
    "    #diff = (datetime.now()+ timedelta(hours=9))-mltime\n",
    "    #input_json['etime_load'] = diff.seconds + diff.microseconds/1E6\n",
    "    input_json['etime_load'] =time.time() - init_time\n",
    "    \n",
    "    ### json insert\n",
    "    input_json['cutoff'] = cut_off\n",
    "    input_json['TRHD_NM_SET'] = \"/\".join([key for key in rule_model_params.keys()])\n",
    "    input_json['TRHD_VAL_SET'] = \"/\".join([str(value) for value in rule_model_params.values()])\n",
    "    input_json['FTUR_NM_SET'] = \"/\".join([\"/\".join([col+'_TEST_N1' for col in column_names]),\n",
    "                                          \"/\".join([col+'_TEST_N2' for col in column_names]),\n",
    "                                          \"/\".join([col+'_TEST_N3' for col in column_names])])\n",
    "    input_json['lid'] = line\n",
    "    input_json['v'] = model_version\n",
    "    \n",
    "    try:\n",
    "        filename = input_path.split('/')[-1]\n",
    "        filename = filename.strip('Data\\\\').split('_')\n",
    "        input_json['bc'] = '_'.join(filename[0:2])\n",
    "        input_json['dtfull'] = filename[2][:-3]\n",
    "\n",
    "    except Exception as ex: # 에러 종류\n",
    "        input_json['bc'] = 'ERROR'\n",
    "        input_json['dtfull'] = str(datetime.now())\n",
    "        input_json['r'] = 2\n",
    "        input_json['prob'] = 2\n",
    "        input_json['error'] = str(ex)\n",
    "        input_json['etime'] = time.time() - init_time\n",
    "\n",
    "        result_json =  [json.dumps(input_json)]\n",
    "        print('*'*5,' ','FILENAME ERROR',' ','*'*5)\n",
    "        print(result_json)\n",
    "        try:\n",
    "            cmd = 'cp ' + input_json['path'] + ' ' + error_dir\n",
    "            os.system(cmd)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    ##-------------Inputs-----------------\n",
    "    md = model_object(cut_off=cut_off,\n",
    "                     rule_params={'FeatureEnergy':{'cut_off':float(rule_model_params['FTUR_ENRG_TRHD'])},\n",
    "                                  'FeatureWaveWindowedSTDMin':{'cut_off':float(rule_model_params['FTUR_WVFM_STDDEV_TRHD'])},\n",
    "                                  'FeatureTriggers':{'cut_off':float(rule_model_params['FTUR_TRGER_TRHD'])}},\n",
    "                     model = loaded_model)\n",
    "\n",
    "    try:\n",
    "        data = pd.DataFrame(input_raw.transpose(), columns=['x1','x2','x3'])\n",
    "        _, pred_y, pred_prob, error, _, data_model = md.run_classifier(input_raw)\n",
    "        input_json['r'] = int(pred_y)\n",
    "        input_json['prob'] = float(pred_prob)\n",
    "        input_json['error'] = str(error)\n",
    "        input_json['etime'] = time.time() - init_time\n",
    "        input_json['FTUR_VAL_SET'] = \"/\".join([str(value) for value in data_model.flatten()])\n",
    "        \n",
    "        result_json =  [json.dumps(input_json)]\n",
    "        print(result_json)\n",
    "    \n",
    "    except Exception as ex: # 에러 종류\n",
    "        input_json['r'] = 2\n",
    "        input_json['prob'] = 2\n",
    "        input_json['error'] = str(ex)\n",
    "        input_json['etime'] = time.time() - init_time\n",
    "        input_json['FTUR_VAL_SET'] = \"\"\n",
    "\n",
    "        result_json =  [json.dumps(input_json)]\n",
    "        print('*'*5,' ','ERROR',' ','*'*5)\n",
    "        print(result_json)\n",
    "        try:\n",
    "            cmd = 'cp ' + input_json['path'] + ' ' + error_dir\n",
    "            os.system(cmd)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    \n",
    "    return result_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    # AZUREML_MODEL_DIR is an environment variable created during deployment.\n",
    "    # It is the path to the model folder (./azureml-models/$MODEL_NAME/$VERSION)\n",
    "    # For multiple models, it points to the folder containing all deployed models (./azureml-models)\n",
    "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'sklearn_mnist_model.pkl')\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "def run(raw_data):\n",
    "    data = np.array(json.loads(raw_data)['data'])\n",
    "    # make prediction\n",
    "    y_hat = model.predict(data)\n",
    "    # you can return any data type as long as it is JSON-serializable\n",
    "    return y_hat.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05 score_iot.py 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06 Azure MLWS 이미지 생성 및 업로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.image import Image, ContainerImage\n",
    "\n",
    "image_config = ContainerImage.image_configuration(runtime= \"python\",\n",
    "                                                  execution_script=\"score_iot.py\",\n",
    "                                                  conda_file=\"data/myenv.yml\",\n",
    "                                                  dependencies=\"../src\",\n",
    "                                                  tags = {'area': \"IoT Edge\", 'type': \"azure-automl\"},\n",
    "                                                  description = IMG_DESC)\n",
    "\n",
    "image = Image.create(name = \"mc-mlmodule\",\n",
    "# image = Image.create(name = \"mc-namtest\",\n",
    "                     # this is the model object \n",
    "                     models = [model],\n",
    "                     image_config = image_config, \n",
    "                     workspace = ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07 이미지 빌드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.wait_for_creation(show_output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 08 빌드 로그 확인 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in Image.list(workspace = ws,tags = [\"area\"]):\n",
    "    print('{}(v.{} [{}]) stored at {} with build log {}'.format(i.name, i.version, i.creation_state, i.image_location, i.image_build_log_uri))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/NotebookVM/tutorials/img-classification-part2-deploy.png)"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "shipatel"
   }
  ],
  "categories": [
   "tutorials",
   "image-classification-mnist-data"
  ],
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "msauthor": "sgilley",
  "network_required": false,
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
